{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import pickle\n",
    "\n",
    "openai.api_key = \"ca392a5651064a37b2207fc766e8a3ae\"\n",
    "openai.api_base = \"https://text-and-code-1.openai.azure.com/\"\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = \"2023-05-15\"\n",
    "deployment_name='gpt-35-turbo-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open('data/data_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_keys = list(data_dict.keys())\n",
    "np.random.shuffle(index_keys)\n",
    "train_keys, test_keys = index_keys[:int(len(index_keys)*0.8)], index_keys[int(len(index_keys)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are WeatherBot, an AI expert in global weather patterns. You will be given a series of monthly average temperatures for some city and some year and asked to predict if the city is in North America or not.\"\n",
    "user_content_1 = \"You will be given the average temperature for each month in Fahrenheit. The average temperatures will be given in list format. For example, if given the list [32, 45, 67, 89, 90, 87, 76, 65, 54, 43, 32, 21], the first number is the average temperature for January, the second number is the average temperature for February, and so on. You will be asked to predict if the city is in North America or not.\"\n",
    "assistant_content_1 = \"Yes I understand. I am WeatherBot, and I will help identify if the city is in North America or not from its average monthly temperatures.\"\n",
    "user_content_2 = \"Great! Let's begin :)\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_ts_label(sample_size, train_data):\n",
    "    ts_list = []\n",
    "    label_list = []\n",
    "    train_keys = list(train_data.keys())\n",
    "    np.random.shuffle(train_keys)\n",
    "    train_keys = train_keys[:sample_size]\n",
    "    for key in train_keys:\n",
    "        sample_ts = train_data[key]['MonthlyAvgTemperature']\n",
    "        sample_label = train_data[key]['Label']\n",
    "        ts_list.append(sample_ts)\n",
    "        label_list.append(sample_label)\n",
    "    return ts_list, label_list\n",
    "\n",
    "def get_test_ts_label(test_data):\n",
    "    return test_data['MonthlyAvgTemperature'], test_data['Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_to_string(ts):\n",
    "    return \"Please answer following this template: (A) This city is in North America OR (B) This city is not in North America.\\nMonthly average temperatures: \" + str(ts)\n",
    "\n",
    "def label_to_string(label):\n",
    "    if label == 1:\n",
    "        return \"(A) This city is in North America.\"\n",
    "    else:\n",
    "        return \"(B) This city is not in North America.\"\n",
    "\n",
    "def parse_response(response_string):\n",
    "    # return 1 if correct, 0 if incorrect, -1 if invalid response\n",
    "    if ('(A)' in response_string and '(B)' in response_string) or ('(A)' not in response_string and '(B)' not in response_string): # invalid response\n",
    "        return -1\n",
    "    else:\n",
    "        return int('(A)' in response_string)\n",
    "    \n",
    "def get_response(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=deployment_name,\n",
    "        messages=prompt,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return response.choices[0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timed_get_response(prompt):\n",
    "    return parse_response(get_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "test_size_global = 100\n",
    "\n",
    "def create_prompt(train_data, test_ts, num_shots):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_content}, {\"role\": \"user\", \"content\": user_content_1}, {\"role\": \"assistant\", \"content\": assistant_content_1}]\n",
    "    messages.append({\"role\": \"user\", \"content\": user_content_2})\n",
    "    train_ts_list, train_label_list = get_train_ts_label(num_shots, train_data)\n",
    "    for i in range(num_shots):\n",
    "        messages.append({\"role\": \"user\", \"content\": ts_to_string(train_ts_list[i])})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": label_to_string(train_label_list[i])})\n",
    "    messages.append({\"role\": \"user\", \"content\": ts_to_string(test_ts)})\n",
    "    return messages\n",
    "\n",
    "\n",
    "def experiment(data_dict, test_size=100, num_shots=4, verbose=True):\n",
    "    global test_size_global\n",
    "    first = True\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    invalid = 0\n",
    "    total = 0\n",
    "    index_keys = list(data_dict.keys())\n",
    "    np.random.shuffle(index_keys)\n",
    "    train_keys, test_keys = index_keys[:int(len(index_keys)*0.8)], index_keys[int(len(index_keys)*0.8):]\n",
    "    train_data = {key: data_dict[key] for key in train_keys}\n",
    "    test_keys = test_keys[:test_size]\n",
    "    responses = []\n",
    "    gts = []\n",
    "    for key in test_keys:\n",
    "        test_ts, test_label = get_test_ts_label(data_dict[key])\n",
    "        prompt = create_prompt(train_data, test_ts, num_shots)\n",
    "        response = parse_response(get_response(prompt))\n",
    "        test_size_global -= 1\n",
    "        time.sleep(.1)\n",
    "        responses.append(response)\n",
    "        gts.append(test_label)\n",
    "        if verbose:\n",
    "            if first:\n",
    "                print(prompt)\n",
    "                first = False\n",
    "            # print('Response:', response, 'GT:', test_label)\n",
    "            if response == -1:\n",
    "                invalid += 1\n",
    "            elif response == test_label:\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect += 1\n",
    "            total += 1\n",
    "            # find true positive rate\n",
    "            tp = (np.array(responses) == np.array(gts)).sum()\n",
    "            fp = (np.array(responses) != np.array(gts)).sum()\n",
    "            tn = (np.array(responses) == np.array(gts)).sum()\n",
    "            fn = (np.array(responses) != np.array(gts)).sum()\n",
    "            recall = tp/(tp + fn)\n",
    "            precision = tp/(tp + fp)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "            try:\n",
    "                print('Accuracy:', round(correct/(incorrect + correct), 3), 'Correct:', correct, 'Incorrect:', incorrect, 'Invalid:', invalid, 'Total', total, 'TP:', tp, 'FP:', fp, 'TN:', tn, 'FN:', fn, 'F1:', round(f1, 3), 'Recall:', round(recall, 3), 'Precision:', round(precision, 3))\n",
    "            except:\n",
    "                print('Accuracy:', 0, 'Correct:', correct, 'Incorrect:', incorrect, 'Invalid:', invalid, 'Total', total, 'TP:', tp, 'FP:', fp, 'TN:', tn, 'FN:', fn, 'F1:', 0, 'Recall:', 0, 'Precision:', 0)\n",
    "\n",
    "    return responses, gts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_size_global == 0:\n",
    "    test_size_global = 100\n",
    "new_test_size = int(test_size_global)\n",
    "results = experiment(data_dict, test_size=new_test_size, num_shots=16, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_content_list = []\n",
    "assistant_content_list = []\n",
    "num_shots = 10\n",
    "for i in range(num_shots):\n",
    "    sample_key = train_keys[i]\n",
    "    sample = data_dict[sample_key]\n",
    "    sample_label = sample['Label']\n",
    "    sample_ts = sample['MonthlyAvgTemperature']\n",
    "    user_content_list.append(\"Please answer following this template: (A) This city is in North America OR (B) This city is not in North America.\\nMonthly average temperatures: \" + str(sample_ts))\n",
    "    assistant_content_list.append(\"(A) This city is in North America\" if sample_label == 1 else \"(B) This city is not in North America\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_content}, {\"role\": \"user\", \"content\": user_content_1}, {\"role\": \"assistant\", \"content\": assistant_content_1}]\n",
    "messages.append({\"role\": \"user\", \"content\": user_content_2})\n",
    "for i in range(num_shots):\n",
    "    messages.append({\"role\": \"user\", \"content\": user_content_list[i]})\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_content_list[i]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 100\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "invalid_response = 0\n",
    "\n",
    "for i in range(test_size):\n",
    "    prompt = messages.copy()\n",
    "    sample_key = test_keys[i]\n",
    "    sample = data_dict[sample_key]\n",
    "    sample_label = sample['Label']\n",
    "    sample_ts = sample['MonthlyAvgTemperature']\n",
    "    user_content = \"Please answer following this template: (A) This city is in North America OR (B) This city is not in North America.\\nMonthly average temperatures: \" + str(sample_ts)\n",
    "    prompt.append({\"role\": \"user\", \"content\": user_content})\n",
    "    # ask the model to predict the label\n",
    "    response = openai.ChatCompletion.create(engine=deployment_name, messages=prompt, temperature=0.0)\n",
    "    if data_dict[sample_key]['Label'] == 1:\n",
    "        look_for = '(A)'\n",
    "        wrong = '(B)'\n",
    "    else:\n",
    "        look_for = '(B)'\n",
    "        wrong = '(A)'\n",
    "    if look_for in response.choices[0]['message']['content'] and wrong in response.choices[0]['message']['content'] or (not look_for in response.choices[0]['message']['content'] and not wrong in response.choices[0]['message']['content']):\n",
    "        invalid_response += 1\n",
    "    else:\n",
    "        if look_for in response.choices[0]['message']['content']:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    print(correct, incorrect, invalid_response)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4, 0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct, incorrect, invalid_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x133016630> JSON: {\n",
       "  \"finish_reason\": \"stop\",\n",
       "  \"index\": 0,\n",
       "  \"message\": {\n",
       "    \"content\": \"(A) This city is in North America\",\n",
       "    \"role\": \"assistant\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test gpt-3-5-turbo deployment\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Mar  8 2023, 04:29:24) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d37db83fe3cff76ae276991fb126ab1d0a2b16b9680b982cc708aa760578f35a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
