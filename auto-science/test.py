import numpy as np
import pandas as pd
import numpy as np
import openai
from utils import get_response, create_prompt, get_test_ts_label, parse_response

openai.api_key = "ca392a5651064a37b2207fc766e8a3ae"
openai.api_base = "https://text-and-code-1.openai.azure.com/"
openai.api_type = 'azure'
openai.api_version = "2023-05-15"
deployment_name='gpt-35-turbo-1'

def test_hypothesis(hypothesis, test_icl_data=None, test_validation_data=None, verbose=True):
    # set up for stat collection
    first = True
    correct = 0
    incorrect = 0
    invalid = 0
    total = 0

    # prompt set up
    system_content = '''You are WeatherBot, an AI expert in global weather patterns. You will be given a series of monthly average temperatures for some city and some year and asked to predict if the city is in North America or not. You will be provided a hypothesis generated by an AI system to help you make your prediction.'''
                        
    user_content_1 = "You will be given the average temperature for each month in Fahrenheit. The average temperatures will be given in list format. For example, if given the list [32, 45, 67, 89, 90, 87, 76, 65, 54, 43, 32, 21], the first number is the average temperature for January, the second number is the average temperature for February, and so on. You will be asked to predict if the city is in North America or not. Please answer following this template: (A) This city is in North America OR (B) This city is not in North America."
    assistant_content_1 = "Yes I understand. I am WeatherBot, and I will help identify if the city is in North America or not from its average monthly temperatures."
    user_content_2 = "Great! Let's begin :)"
    hypothesis_prompt = 'Hypothesis: ' + hypothesis
    # TODO: should hypothesis be at the beginning or the end?
    # experiment
    test_keys = list(test_validation_data.keys())
    np.random.shuffle(test_keys)
    responses = []
    gts = []
    for key in test_keys:
        # TODO: messy and repetitive
        test_sample = test_validation_data[key]
        test_ts, test_label = get_test_ts_label(test_sample)
        messages = [{"role": "system", "content": system_content}, {"role": "user", "content": user_content_1}, {"role": "assistant", "content": assistant_content_1}, {"role": "user", "content": user_content_2}, {"role": "user", "content": hypothesis_prompt}]
        # messages = [{"role": "system", "content": system_content}, {"role": "user", "content": user_content_1}, {"role": "assistant", "content": assistant_content_1}, {"role": "user", "content": user_content_2}]

        prompt = create_prompt(num_shots=1, train_data=test_icl_data, test_data=test_sample, train_mode=True, test_mode=True, messages=messages)
        last_message = prompt.pop()
        prompt.append({'role': 'user', 'content': 'As a reminder, this is the hypothesis: ' + hypothesis})
        prompt.append(last_message)
        if first and verbose:
            for el in prompt:
                print(el['content'])
                print()
        print(len(prompt))
        response_text = get_response(prompt, temperature=0.0)
        if first and verbose:
            print(response_text)
        response = parse_response(response_text)
        responses.append(response)
        gts.append(test_label)
        print(test_ts, test_label, response)
        if verbose:
            if first:
                first = False
            if response == -1:
                invalid += 1
            elif response == test_label:
                correct += 1
            else:
                incorrect += 1
            total += 1
            # find true positive rate
            tp = (np.array(responses) == np.array(gts)).sum()
            fp = (np.array(responses) != np.array(gts)).sum()
            tn = (np.array(responses) == np.array(gts)).sum()
            fn = (np.array(responses) != np.array(gts)).sum()
            recall = tp/(tp + fn)
            precision = tp/(tp + fp)
            f1 = 2 * (precision * recall) / (precision + recall)
            try:
                print('Accuracy:', round(correct/(incorrect + correct), 3), 'Correct:', correct, 'Incorrect:', incorrect, 'Invalid:', invalid, 'Total', total, 'TP:', tp, 'FP:', fp, 'TN:', tn, 'FN:', fn, 'F1:', round(f1, 3), 'Recall:', round(recall, 3), 'Precision:', round(precision, 3))
            except:
                print('Accuracy:', 0, 'Correct:', correct, 'Incorrect:', incorrect, 'Invalid:', invalid, 'Total', total, 'TP:', tp, 'FP:', fp, 'TN:', tn, 'FN:', fn, 'F1:', 0, 'Recall:', 0, 'Precision:', 0)
    return responses, gts

